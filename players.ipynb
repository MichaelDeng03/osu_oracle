{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEPRECATED**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary goal of this notebook is to scrape for player data. Trying to find data for many players. \n",
    "# Method is scraping leaderboards of (all) countries. This is better than just one/global lb because leaderboards only go up to\n",
    "# 10k, and we would like more. Then, individually scrape each player's profile for more data.\n",
    "\n",
    "from ossapi import Ossapi\n",
    "from ossapi import Cursor\n",
    "import pycountry\n",
    "import sqlite3 \n",
    "import pandas as pd\n",
    "import plyvel\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "import ossapi.models\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import asyncio\n",
    "from ossapi import Ossapi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Scrape a list of valid user_ids\n",
    "Go through leaderboards of all countries to get the most number of unique players. Else, limited to 10k. \n",
    "Don't really want to BFS for players, and no other (good) way to get more than 10k players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"28051\"\n",
    "client_secret = \"Ry1MCvj2OHJ1mK19M9x1j1sUNFwLQdeJb8Xpfegs\"\n",
    "api = Ossapi(client_id, client_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data/osu_recommender.db')\n",
    "sql_cursor = conn.cursor()\n",
    "seen_users = set(sql_cursor.execute(\"SELECT user_id FROM players\").fetchall()) \n",
    "to_insert = [] # Cache for batch write optimization. \n",
    "\n",
    "def add_player(user_id, pp, seen_users = seen_users, to_insert = to_insert):\n",
    "    \"\"\"\n",
    "    Adds a player to player table in db if not already seen. Only has player and pp information. \n",
    "    user_id: integer user_id\n",
    "    pp: Total pp (float) for that player. \n",
    "    seen_users: A set of user_ids already in database/queued for insertion.\n",
    "    to_insert: A queue of user_ids queued/cached for insertion. \n",
    "    \"\"\"\n",
    "    if user_id not in seen_users:\n",
    "        seen_users.add(user_id)\n",
    "        to_insert.append((user_id, pp))\n",
    "        \n",
    "    if len(to_insert) >= 1000:\n",
    "        sql_cursor.executemany('INSERT INTO players (user_id, pp) VALUES (?, ?)', to_insert)\n",
    "        to_insert.clear()\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQ\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country AQ doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "TF\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country TF doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "EH\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country EH doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "HM\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country HM doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "KP\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country KP doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "GS\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country GS doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "SH\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country SH doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "SS\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country SS doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "UM\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country UM doesnt exist (probably). Skipping, and not updating completed_countries\n",
      "VA\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Country VA doesnt exist (probably). Skipping, and not updating completed_countries\n"
     ]
    }
   ],
   "source": [
    "country_codes = [country.alpha_2 for country in pycountry.countries]\n",
    "completed_countries = sql_cursor.execute(\"SELECT country_alpha_2 FROM completed_countries\").fetchall()\n",
    "completed_countries = [country[0] for country in completed_countries]\n",
    "remaining_countries = [country for country in country_codes if country not in set(completed_countries)]\n",
    "\n",
    "for country in remaining_countries:\n",
    "    print(country)\n",
    "    try:\n",
    "        lb_cursor = Cursor(page=1)\n",
    "        while lb_cursor is not None: # Cursor will be none if we have reached the end of the leaderboard\n",
    "            rankings = api.ranking(mode = \"osu\", type = \"performance\", cursor = lb_cursor, country = country)\n",
    "            lb_cursor = rankings.cursor # Update cursor\n",
    "            \n",
    "            for user_stats in rankings.ranking:\n",
    "                if user_stats.pp < 500:\n",
    "                    break # Don't add players with less than 500pp. Minor speed up. \n",
    "                add_player(user_stats.user.id, user_stats.pp)\n",
    "    except ValueError as e: # Sometimes the country doesn't have a leader board. (I think 6 of 249)\n",
    "        print(e)\n",
    "        print(f'Country {country} doesnt exist (probably). Skipping, and not updating completed_countries')\n",
    "        continue        \n",
    "    except KeyboardInterrupt as e:\n",
    "        print(e)\n",
    "        print('You keyboard interrupted. Saving progress and exiting.')\n",
    "        # Save progress and exit\n",
    "        sql_cursor.executemany('INSERT INTO players (user_id, pp) VALUES (?, ?)', to_insert)\n",
    "        conn.commit()\n",
    "        to_insert.clear()\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('uhhhhh')\n",
    "        raise e\n",
    "    \n",
    "    # Add country to completed countries\n",
    "    sql_cursor.execute(f'INSERT INTO completed_countries (country_alpha_2) VALUES (\"{country}\")')\n",
    "    conn.commit()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2983479,\n",
       " 3963421,\n",
       " 4033854,\n",
       " 3962022,\n",
       " 3967160,\n",
       " 3665005,\n",
       " 3355394,\n",
       " 2111505,\n",
       " 3873445,\n",
       " 2684029,\n",
       " 2597236,\n",
       " 1651290,\n",
       " 3906726,\n",
       " 2659369,\n",
       " 2567509,\n",
       " 1632673,\n",
       " 898576,\n",
       " 931597,\n",
       " 2902017,\n",
       " 2570594,\n",
       " 904687,\n",
       " 1938365,\n",
       " 713442,\n",
       " 2330357,\n",
       " 738063,\n",
       " 1100265,\n",
       " 2444149,\n",
       " 2316176,\n",
       " 2185824,\n",
       " 827803,\n",
       " 3874766,\n",
       " 1194389,\n",
       " 1572868,\n",
       " 1621068,\n",
       " 2419085,\n",
       " 3933758,\n",
       " 1610745,\n",
       " 1619555,\n",
       " 1702172,\n",
       " 930249,\n",
       " 1706834,\n",
       " 735272,\n",
       " 1829998,\n",
       " 723891,\n",
       " 2469345,\n",
       " 1848919,\n",
       " 1483372,\n",
       " 827488,\n",
       " 2245766,\n",
       " 760488,\n",
       " 2166311,\n",
       " 1924025,\n",
       " 2415690,\n",
       " 2245774,\n",
       " 884664,\n",
       " 3069848,\n",
       " 1643270,\n",
       " 1726474,\n",
       " 1612454,\n",
       " 1165064,\n",
       " 933875,\n",
       " 1655981,\n",
       " 2237470,\n",
       " 1716732,\n",
       " 147327,\n",
       " 1744385,\n",
       " 3561624,\n",
       " 1033739,\n",
       " 1849120,\n",
       " 2615748,\n",
       " 2034983,\n",
       " 2036365,\n",
       " 2570165,\n",
       " 1018869,\n",
       " 3628459,\n",
       " 3853713,\n",
       " 2778999,\n",
       " 602259,\n",
       " 1645698,\n",
       " 1827323,\n",
       " 2887834,\n",
       " 2331417,\n",
       " 1897995,\n",
       " 2246465,\n",
       " 1186443,\n",
       " 1023307,\n",
       " 2606880,\n",
       " 2168425,\n",
       " 2872154,\n",
       " 1828339,\n",
       " 2510778,\n",
       " 2025938,\n",
       " 1588369,\n",
       " 1032126,\n",
       " 1642274,\n",
       " 3746239,\n",
       " 2059455,\n",
       " 2067426,\n",
       " 1897577,\n",
       " 2826730]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# user_ids = players['user_id'].values\n",
    "# user_id = user_ids[0]\n",
    "# user = api.user(user_id, mode ='osu', key='id') \n",
    "# user_scores = api.user_scores(user_id, type='best', mode='osu', limit=100)\n",
    "# user_beatmaps = [user_score.beatmap.id  for user_score in user_scores]\n",
    "# user_beatmaps\n",
    "\n",
    "# # Temporarily work on backup db\n",
    "\n",
    "# user_ids = cursor.execute('SELECT user_id FROM players').fetchall()\n",
    "# user_ids = [user_id[0] for user_id in user_ids]\n",
    "# for user_id in user_ids:\n",
    "#     user = api.user(user_id, mode ='osu', key='id')\n",
    "#     user_scores = api.user_scores(user_id, type='best', mode='osu', limit=100)\n",
    "#     user_beatmaps = [user_score.beatmap.id  for user_score in user_scores]\n",
    "#     # Would like to keep one row for each.... Unless we can do some cassandra shit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Get user top play data. \n",
    " Realize that relational database has no like benefits.... In fact, going to migrate away to a levelDB because I only need key:val pairs, and I would like to be able to store (byte) objects. Furthermore, stoarge is becoming a concern. 400,000 users, with 100 top plays each. Each play being 1KB? 40GB of data. Not impossible, but I value my storage space.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle can't serialize functions in User class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Classes for serialization and storage purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Beatmap:\n",
    "    \"\"\"\n",
    "    Keeps select attributes from ossapi.models.Beatmap\n",
    "    \"\"\"\n",
    "    def __init__(self, beatmap: ossapi.models.Beatmap):\n",
    "        self.accuracy = beatmap.accuracy\n",
    "        self.ar = beatmap.ar\n",
    "        self.beatmapset_id = beatmap.beatmapset_id\n",
    "        self.bpm = beatmap.bpm\n",
    "        self.cs = beatmap.cs\n",
    "        self.count_circles = beatmap.count_circles\n",
    "        self.count_sliders = beatmap.count_sliders\n",
    "        self.count_spinners = beatmap.count_spinners\n",
    "        self.difficulty_rating = beatmap.difficulty_rating\n",
    "        self.beatmap_id = beatmap.id\n",
    "        self.max_combo = beatmap.max_combo\n",
    "        self.drain = beatmap.drain\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Score:\n",
    "    \"\"\"\n",
    "    Keeps select attributes from ossapi.models.Score\n",
    "    \"\"\"\n",
    "    def __init__(self, score: ossapi.models.Score):\n",
    "        self.accuracy = score.accuracy\n",
    "        self.score_id = score.id # \n",
    "        self.pp = score.pp\n",
    "        self.perfect = score.perfect\n",
    "        self.mods = score.mods.value # Bitwise enumeration of mods. https://github.com/ppy/osu-api/wiki#mods\n",
    "        self.beatmap = Beatmap(score.beatmap)\n",
    "        \n",
    "@dataclass\n",
    "class UserTopScores:\n",
    "    \"\"\"\n",
    "    Class for tracking an osu player's top scores. Similar to return type of ossapi.user_scores() = list[Score]. \n",
    "    Keeps only select attributes for storage and pickling purposes. \n",
    "    \"\"\"\n",
    "    def __init__(self, user_id, top_scores):\n",
    "        self.user_id = user_id\n",
    "        self.scores = []\n",
    "        top_scores\n",
    "        for score in top_scores:\n",
    "            self.scores.append(Score(score)) \n",
    "            \n",
    "async def pull_top_scores(api, user_id):\n",
    "    \"\"\"\n",
    "    Asynchronously pulls top scores from asynch ossapi\n",
    "    \"\"\"\n",
    "    top_scores = await api.user_scores(user_id, type = 'best', mode = 'osu', limit = 100)\n",
    "    return (user_id, top_scores)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage DB's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    playerDB.close()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "playerDB = plyvel.DB('data/playerDB', create_if_missing=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    conn.close()\n",
    "except:\n",
    "    print(e)\n",
    "sql_conn = sqlite3.connect('data/osu_recommender.db')\n",
    "\n",
    "# Need async api for following\n",
    "async_api = Ossapi(client_id, client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over user_ids.\n",
    "Networked I/O blocked. Need to multi-thread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: 0.23535633087158203\n",
      "200: 0.002130270004272461\n",
      "300: 0.0014386177062988281\n",
      "400: 0.0018777847290039062\n",
      "500: 0.0018413066864013672\n",
      "600: 0.0013065338134765625\n",
      "700: 0.002015829086303711\n",
      "800: 0.0017189979553222656\n",
      "900: 0.0014846324920654297\n",
      "1000: 0.0015342235565185547\n",
      "1100: 0.0017323493957519531\n",
      "1200: 0.002088785171508789\n",
      "1300: 0.0018765926361083984\n",
      "1400: 0.0017540454864501953\n",
      "1500: 0.002164602279663086\n",
      "1600: 0.0019135475158691406\n",
      "1700: 0.0017082691192626953\n",
      "1800: 0.001783132553100586\n",
      "1900: 0.002758502960205078\n",
      "2000: 0.001947164535522461\n",
      "2100: 0.0033960342407226562\n",
      "2200: 0.0053806304931640625\n",
      "2300: 0.006060600280761719\n",
      "2400: 0.005263328552246094\n",
      "2500: 0.0049021244049072266\n",
      "2600: 0.004897117614746094\n",
      "2700: 0.005650520324707031\n",
      "2800: 0.005185604095458984\n",
      "2900: 0.00496673583984375\n",
      "3000: 0.004995584487915039\n",
      "3100: 0.005558013916015625\n",
      "3200: 0.0050792694091796875\n",
      "3300: 0.0049936771392822266\n",
      "3400: 0.005563020706176758\n",
      "3500: 0.005673885345458984\n",
      "3600: 0.005368709564208984\n",
      "3700: 0.0050201416015625\n",
      "3800: 0.0053861141204833984\n",
      "3900: 0.005268573760986328\n",
      "4000: 0.005125284194946289\n",
      "4100: 0.0055277347564697266\n",
      "4200: 0.005268096923828125\n",
      "4300: 0.006207466125488281\n",
      "4400: 0.005074262619018555\n",
      "4500: 0.0063135623931884766\n",
      "4600: 0.006128787994384766\n",
      "4700: 0.004903554916381836\n",
      "4800: 0.004984617233276367\n",
      "4900: 0.004859447479248047\n",
      "5000: 0.0048558712005615234\n",
      "5100: 0.005294322967529297\n",
      "5200: 0.0051839351654052734\n",
      "5300: 0.005132436752319336\n",
      "5400: 0.004883766174316406\n",
      "5500: 0.005248546600341797\n",
      "5600: 0.005356788635253906\n",
      "5700: 0.005693197250366211\n",
      "5800: 0.004832267761230469\n",
      "5900: 0.004789590835571289\n",
      "6000: 0.004828691482543945\n",
      "6100: 0.00479578971862793\n",
      "6200: 0.004786968231201172\n",
      "6300: 0.0050809383392333984\n",
      "6400: 0.0047528743743896484\n",
      "6500: 0.0048847198486328125\n",
      "6600: 0.004698991775512695\n",
      "6700: 0.004677772521972656\n",
      "6800: 0.0047991275787353516\n",
      "6900: 0.004693031311035156\n",
      "7000: 0.0046482086181640625\n",
      "7100: 0.00475001335144043\n",
      "7200: 0.004682779312133789\n",
      "7300: 0.004636049270629883\n"
     ]
    }
   ],
   "source": [
    "lock = threading.Lock()\n",
    "num_done = 0\n",
    "last_time = time.time()\n",
    "def scrape_top_scores(user_ids_subset, playerDB = playerDB):\n",
    "    \"\"\"\n",
    "    Work function for multithreading scraping of user_id top scores.\n",
    "    Not going to lock because shouldn't be possible to have concurrent accesses to same key. Terrible programming practice though. \n",
    "    \"\"\"\n",
    "    global num_done\n",
    "    global last_time\n",
    "    for user_id in user_ids_subset:\n",
    "        ser_user_id = pickle.dumps(user_id)\n",
    "        if playerDB.get(ser_user_id) is None: \n",
    "            user_top_scores =  UserTopScores(user_id, async_api)\n",
    "            ser_user_top_scores = pickle.dumps(user_top_scores)\n",
    "            playerDB.put(ser_user_id, ser_user_top_scores)\n",
    "    \n",
    "        num_done += 1\n",
    "        if num_done % 100 == 0:\n",
    "            print(str(num_done) + \": \" + str(time.time() - last_time))\n",
    "            last_time = time.time()\n",
    "\n",
    "# Need to partition user_ids so that each thread does different keys. \n",
    "user_ids = pd.read_sql_query(\"SELECT user_id FROM players\", sql_conn)\n",
    "user_ids = list(user_ids['user_id'])\n",
    "num_partitions = 5\n",
    "size_partition = len(user_ids) // num_partitions\n",
    "p_user_ids = [user_ids[i:i + size_partition] for i in range(0, (len(user_ids)//num_partitions)*num_partitions, size_partition)]\n",
    "if len(user_ids) % num_partitions != 0:\n",
    "    p_user_ids[-1].extend(user_ids[(len(user_ids)//num_partitions)*num_partitions:])\n",
    "    \n",
    "with ThreadPoolExecutor(max_workers=num_partitions) as executor:\n",
    "    for user_ids in p_user_ids:\n",
    "        executor.submit(scrape_top_scores, user_ids)\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
